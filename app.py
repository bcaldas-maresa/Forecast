import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import base64
from sqlalchemy import create_engine, text
from datetime import datetime
from sklearn.linear_model import LinearRegression
from math import isnan
from auth import login_user  # Tu funci√≥n de login
from db import get_engine
from sidebar import render_sidebar


engine = get_engine()

# =============================
# CAT√ÅLOGO DE DRIVERS (Ficha T√©cnica)
# =============================

def normalize_driver_key(v: str) -> str:
    """Normaliza el nombre de variable para matchear con el cat√°logo."""
    if v is None:
        return ""
    k = str(v).strip().upper()
    k = k.replace(" ", "_").replace(".", "_")
    return k

DRIVER_CATALOG = {
    "IVA": {
        "tipo": "Fiscal / Demanda agregada",
        "porque": "Proxy de consumo formal y actividad comercial; suele moverse con ventas de bienes durables y servicios asociados (talleres, repuestos).",
        "fuente": "SRI",
    },
    "WTI": {
        "tipo": "Commodities / Energ√≠a",
        "porque": "Afecta costos log√≠sticos y expectativas macro; en Ecuador tambi√©n incide en ingresos petroleros ‚Üí gasto/actividad y liquidez.",
        "fuente": "https://es.investing.com/commodities/crude-oil",
    },
    "euro_usd": {
        "tipo": "Tipo de cambio externo",
        "porque": "Influye en el costo de importaci√≥n desde Europa (veh√≠culos/partes) y en precios relativos de proveedores.",
        "fuente": "https://es.investing.com/currencies/eur-usd",
    },
    "PVP_ORO_1_OZ": {
        "tipo": "Commodities / Financiero",
        "porque": "Indicador de aversi√≥n al riesgo global; cuando sube fuerte suele coincidir con menor apetito por cr√©dito/consumo durable.",
        "fuente": "https://es.investing.com/commodities/gold",
    },
    "PIB_DEM_CAD_BRU": {
        "tipo": "Actividad real",
        "porque": "Captura el ciclo econ√≥mico: en expansi√≥n suben ingresos, empleo y confianza ‚Üí m√°s compras de veh√≠culos.",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/cuentasnacionales/ix_cuentasnacionalestrimestrales.html",
    },
    "DEMINT_CORR_AJUS": {
        "tipo": "Demanda interna",
        "porque": "Mide el pulso de consumo + inversi√≥n dom√©stica, que son motores directos de ventas de autos (particulares y flotas).",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/cuentasnacionales/ix_cuentasnacionalestrimestrales.html",
    },
    "PIB_CAD_AJUS": {
        "tipo": "Actividad real",
        "porque": "Serie ‚Äúlimpia‚Äù (ajustada) para modelar tendencia/ciclo sin ruido estacional; mejora forecast de demanda automotriz.",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/cuentasnacionales/ix_cuentasnacionalestrimestrales.html",
    },
    "ING_PETROLEO": {
        "tipo": "Fiscal / Petrolero",
        "porque": "M√°s ingresos petroleros suelen traducirse en m√°s gasto p√∫blico/liquidez, mejorando empleo y consumo, impactando ventas.",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/cuentasnacionales/ix_cuentasnacionalestrimestrales.html",
    },
    "PETRO_PROD": {
        "tipo": "Real / Petrolero",
        "porque": "Anticipa ingresos del sector y dinamismo macro; tambi√©n incide en transporte/actividad productiva y consumo.",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/cuentasnacionales/ix_cuentasnacionalestrimestrales.html",
    },
    "IPC": {
        "tipo": "Precios",
        "porque": "Inflaci√≥n alta erosiona poder adquisitivo, encarece operaci√≥n (servicios) y puede frenar compras de durables.",
        "fuente": "https://app.powerbi.com/view?r=eyJrIjoiMjM5MmZiYTUtYWJhOC00ZjQ3LTg3YWYtM2I4YTBhMmRiYmRhIiwidCI6ImYxNThhMmU4LWNhZWMtNDQwNi1iMGFiLWY1ZTI1OWJkYTExMiJ9",
    },
    "INFLACIONMENSUAL": {
        "tipo": "Precios (derivada)",
        "porque": "Detecta shocks recientes de precios; √∫til para ajustar timing del consumo y sensibilidad al financiamiento.",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/indicadores/real/Inflacion.html",
    },
    "CREDITOSECTORPRIVADO": {
        "tipo": "Financiera / Cr√©dito",
        "porque": "La compra de autos depende mucho del financiamiento; m√°s cr√©dito disponible suele elevar ventas.",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/MonetarioFinanciero/ix_MonetariasFinancierasPrin.html",
    },
    "DEPOSITOSALAVISTA": {
        "tipo": "Liquidez",
        "porque": "Indica liquidez del sistema y capacidad de colocaci√≥n de cr√©dito; tambi√©n refleja confianza/ingreso corriente.",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/MonetarioFinanciero/ix_MonetariasFinancierasPrin.html",
    },
    "ICC": {
        "tipo": "Expectativas",
        "porque": "La decisi√≥n de comprar auto es sensible a confianza; ICC captura disposici√≥n a gastar y percepci√≥n de futuro.",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/indicadores/real/IndiceConfianzaConsumidor.html",
    },
    "EMPLEOADECUADOPLENO": {
        "tipo": "Laboral",
        "porque": "Mejor empleo ‚Üí m√°s ingreso estable ‚Üí mayor aprobaci√≥n de cr√©dito y m√°s demanda de veh√≠culos.",
        "fuente": "https://app.powerbi.com/view?r=eyJrIjoiNDY3MjljMTYtNGI5Yy00ZWM4LWE4OTYtNjlhYWYxYzcwZTAxIiwidCI6ImYxNThhMmU4LWNhZWMtNDQwNi1iMGFiLWY1ZTI1OWJkYTExMiJ9",
    },
    "IMP_CBU": {
        "tipo": "Comercio exterior",
        "porque": "Veh√≠culos suelen llegar como CBU; es un leading indicator de oferta/ventas futuras (importas hoy, vendes despu√©s).",
        "fuente": "Veritrade",
    },
    "RIESGO_PAIS": {
        "tipo": "Riesgo / Mercado",
        "porque": "Afecta costo de fondeo, tasas, disponibilidad de cr√©dito y confianza; alto riesgo suele frenar inversi√≥n/consumo durable.",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/PublicacionesGenerales/ix_PublicacionesGeneralesPrin.html",
    },
    "TASA_DE_INTERES_ACTIVA": {
        "tipo": "Tasas",
        "porque": "Determina cuota y costo total de financiamiento; subidas de tasa reducen demanda de veh√≠culos a cr√©dito.",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/MonetarioFinanciero/ix_MonetariasFinancierasPrin.html",
    },
    "CARTERA_CREDITOS_DE_CONSUMO": {
        "tipo": "Cr√©dito (segmento)",
        "porque": "Proxy directo de din√°mica de cr√©dito al hogar; correlaciona con ventas de autos y motos.",
        "fuente": "https://contenido.bce.fin.ec/documentos/informacioneconomica/MonetarioFinanciero/ix_MonetariasFinancierasPrin.html",
    },
    "UTILIDADES": {"tipo": "Resultados / Ingreso", "porque": "(Seg√∫n definici√≥n) utilidades sectoriales o financieras reflejan capacidad de inversi√≥n (flotas) y solvencia del sistema para prestar.", "fuente": "Dummy"},
    "PARO": {"tipo": "Laboral", "porque": "Mayor desempleo reduce intenci√≥n de compra y aumenta riesgo crediticio ‚Üí menor colocaci√≥n de cr√©ditos de auto.", "fuente": "Dummy"},
    "CUP_IMPORT": {"tipo": "Comercio exterior (costo)", "porque": "Aproxima costo unitario importado; subidas anticipan alzas de precios de veh√≠culos/repuestos y posibles ca√≠das de volumen.", "fuente": "Dummy"},
    "ELEC_PRESIDENCIALES": {"tipo": "Evento / Pol√≠tica", "porque": "Periodos electorales suelen mover expectativas e inversi√≥n; puede haber postergaci√≥n de compras o shocks de demanda.", "fuente": "Dummy"},
    "CAMBIO_IVA": {"tipo": "Pol√≠tica fiscal", "porque": "Cambios de IVA alteran el precio final (veh√≠culo, servicios y repuestos) y pueden generar adelanto/atraso de compras.", "fuente": "Dummy"},
    "DUMMY_COVID_LOCKDOWN": {"tipo": "Shock ex√≥geno", "porque": "Captura quiebres estructurales: cierres reducen ventas, importaciones, empleo y cr√©dito; evita que el modelo ‚Äúaprenda mal‚Äù.", "fuente": "Dummy"},
}

# =============================
# CONFIGURACI√ìN INICIAL
# =============================

if 'logged_in' not in st.session_state:
    st.session_state['logged_in'] = False
if 'is_admin' not in st.session_state:
    st.session_state['is_admin'] = False
if 'email' not in st.session_state:
    st.session_state['email'] = ""
if 'df_desagregado' not in st.session_state:
    st.session_state['df_desagregado'] = None
if 'meses_share_modelo' not in st.session_state:
    st.session_state['meses_share_modelo'] = 3
if 'selected_forecast_name' not in st.session_state:
    st.session_state['selected_forecast_name'] = None
if 'df_total_forecast' not in st.session_state:
    st.session_state['df_total_forecast'] = None

# Config de p√°gina seg√∫n login
if not st.session_state['logged_in']:
    st.set_page_config(layout="centered", initial_sidebar_state="collapsed")
    st.markdown(
        """
        <style>
            [data-testid="stSidebar"] {
                display: none;
            }
        </style>
        """,
        unsafe_allow_html=True
    )
else:
    st.set_page_config(layout="wide", initial_sidebar_state="expanded")
    
# Lista de dummies para clasificar drivers en la ficha t√©cnica
DUMMY_VARS_LIST = [
    'CUP_IMPORT', 'CAMBIO_IVA', 'ELEC_PRESIDENCIALES', 'PARO', 'UTILIDADES',
    'DUMMY_COVID_LOCKDOWN'
]


# Descripciones y fuentes sugeridas para algunos drivers macro
DRIVER_DESCRIPTIONS = {
    "PIB": "Crecimiento real del Producto Interno Bruto de Ecuador.",
    "RIESGO_PAIS": "√çndice de riesgo pa√≠s (spread EMBI u otro √≠ndice equivalente).",
    "TASA_DESEMPLEO": "Tasa de desempleo nacional.",
    "TC_PROMEDIO": "Tipo de cambio promedio utilizado en las importaciones.",
    "TASA_INTERES": "Tasa de inter√©s referencial / cr√©dito de consumo.",
}

DRIVER_SOURCES = {
    "PIB": "Banco Central del Ecuador (BCE).",
    "RIESGO_PAIS": "Fuentes internacionales (p. ej. JP Morgan EMBI) procesadas por Maresa.",
    "TASA_DESEMPLEO": "INEC / publicaciones oficiales.",
    "TC_PROMEDIO": "BCE / sistema financiero.",
    "TASA_INTERES": "BCE / Superintendencia de Bancos.",
}


@st.cache_resource
def get_db_engine():
    try:
        engine = get_engine()
        return engine
    except Exception as e:
        st.error(f"Error al crear conexi√≥n a BD: {e}")
        st.stop()


@st.cache_data(ttl=600)
def load_all_forecast_names():
    """Nombres de proyecciones guardadas en forecast_final_projections."""
    try:
        engine = get_db_engine()
        sql = """
            SELECT projection_name, MAX(created_at) as last_created 
            FROM forecast_final_projections 
            GROUP BY projection_name 
            ORDER BY last_created DESC
        """
        df = pd.read_sql(sql, engine)
        return df['projection_name'].tolist()
    except Exception as e:
        st.error(f"Error al cargar nombres de forecast: {e}")
        return []


@st.cache_data(ttl=600)
def load_selected_forecast(projection_name):
    """
    Carga la proyecci√≥n TOTAL (industria) de forecast_final_projections para un projection_name.

    Devuelve un DF pivot:
      index = fecha
      columns = ['Ventas_Normal', 'Ventas_Optimista', 'Ventas_Pesimista']
    """
    try:
        engine = get_db_engine()
        sql = text("""
            SELECT fecha, tipo_escenario, valor_proyectado 
            FROM forecast_final_projections 
            WHERE projection_name = :name
        """)
        df = pd.read_sql(sql, engine, params={"name": projection_name}, parse_dates=['fecha'])

        df_pivot = df.pivot_table(
            index='fecha',
            columns='tipo_escenario',
            values='valor_proyectado'
        ).rename(columns={
            'Normal': 'Ventas_Normal',
            'Optimista': 'Ventas_Optimista',
            'Pesimista': 'Ventas_Pesimista'
        })
        return df_pivot
    except Exception as e:
        st.error(f"Error al cargar forecast seleccionado: {e}")
        return pd.DataFrame()


@st.cache_data(ttl=600)
def load_all_granular_sales():
    """
    Carga ventas hist√≥ricas granulares desde sales_granular.
    Agrupa a nivel (mes, segmento, marca, modelo, provincia).
    """
    try:
        engine = get_db_engine()
        sql = """
            SELECT 
                date_trunc('month', fecha_proceso)::date as "Fecha",
                segmento,
                marca,
                familia,
                modelo,
                provincia,
                SUM(unidades) as "Unidades"
            FROM sales_granular
            GROUP BY 1, 2, 3, 4, 5, 6
        """
        df = pd.read_sql(sql, engine, parse_dates=['Fecha'])
        return df
    except Exception as e:
        st.error(f"Error al cargar ventas granulares: {e}")
        return pd.DataFrame()
    
# =============================
# FUNCIONES PARA FICHA T√âCNICA
# =============================

@st.cache_data
def load_projection_catalog(_engine):
    """
    Cat√°logo de proyecciones guardadas:
    una fila por (projection_name, segmento_base, modelo_usado),
    usando el scenario_name NO NULO cuando exista.
    """
    query = text("""
        SELECT 
            projection_name,
            segmento_base,
            modelo_usado,
            MAX(scenario_name) AS scenario_name
        FROM forecast_final_projections
        GROUP BY projection_name, segmento_base, modelo_usado
        ORDER BY projection_name
    """)
    with _engine.connect() as conn:
        df = pd.read_sql(query, conn)
    return df



@st.cache_data(ttl=600)
def load_projection_metrics(_engine, projection_name):
    """
    Devuelve:
      - df_run: una fila de forecast_runs (scope, best_model, etc.)
      - df_metrics: tabla de m√©tricas por modelo desde forecast_model_metrics
    """
    with _engine.connect() as conn:
        # Resumen de la corrida (forecast_runs)
        df_run = pd.read_sql(
            text("""
                SELECT projection_name, scope, horizon_months,
                       train_start, train_end, test_start, test_end,
                       best_model, best_mape, best_mae, best_rmse
                FROM forecast_runs
                WHERE projection_name = :p
                ORDER BY train_start DESC
                LIMIT 1
            """),
            conn,
            params={"p": projection_name},
            parse_dates=['train_start', 'train_end', 'test_start', 'test_end']
        )

        # Leaderboard por modelo (forecast_model_metrics) -> AQU√ç NO hay 'scope'
        df_metrics = pd.read_sql(
            text("""
                SELECT projection_name, model_name, mape, mae, rmse
                FROM forecast_model_metrics
                WHERE projection_name = :p
                ORDER BY mape ASC
            """),
            conn,
            params={"p": projection_name},
        )

    return df_run, df_metrics


@st.cache_data
def load_projection_variables(_engine, scenario_name: str):
    """
    Carga las variables (drivers) usadas en el escenario de drivers asociado
    a la proyecci√≥n.
    """
    if not scenario_name or (isinstance(scenario_name, float) and np.isnan(scenario_name)):
        return pd.DataFrame()

    with _engine.connect() as conn:
        df_vars = pd.read_sql(
            text("""
                SELECT DISTINCT variable
                FROM forecast_driver_scenarios
                WHERE scenario_name = :s
                ORDER BY variable
            """),
            conn,
            params={"s": scenario_name},
        )
    return df_vars


@st.cache_data(ttl=600)
def load_historical_drivers_for_ft(_engine):
    """Carga la tabla historical_drivers para la ficha t√©cnica."""
    with _engine.connect() as conn:
        try:
            df_hist = pd.read_sql("SELECT * FROM historical_drivers", conn, parse_dates=["Fecha"])
        except Exception:
            # Si la tabla no existe o tiene un esquema distinto, devolvemos DF vac√≠o
            return pd.DataFrame()
    return df_hist


@st.cache_data(ttl=600)
def build_driver_summary_for_scenario(_engine, scenario_name: str):
    """Devuelve un resumen por variable con √∫ltimo valor real, √∫ltimo valor proyectado
    y variaci√≥n porcentual para el escenario indicado."""
    if not scenario_name or (isinstance(scenario_name, float) and np.isnan(scenario_name)):
        return pd.DataFrame()

    # Variables del escenario (lista base)
    df_vars = load_projection_variables(_engine, scenario_name)
    if df_vars.empty:
        return df_vars

    # Hist√≥rico de drivers (ancho -> largo)
    df_hist = load_historical_drivers_for_ft(_engine)
    if df_hist.empty or "Fecha" not in df_hist.columns:
        df_vars["valor_real"] = np.nan
        df_vars["valor_proyectado"] = np.nan
        df_vars["Variacion_pct"] = np.nan
        df_vars["Descripcion"] = df_vars["variable"].apply(
            lambda v: DRIVER_DESCRIPTIONS.get(str(v).upper(), "Driver macro / de negocio.")
        )
        df_vars["Fuente"] = df_vars["variable"].apply(
            lambda v: DRIVER_SOURCES.get(str(v).upper(), "Maresa / fuentes internas y p√∫blicas.")
        )
        return df_vars

    hist_melt = df_hist.melt(id_vars="Fecha", var_name="variable", value_name="valor_real")
    # √öltimo valor real por variable
    idx_hr = hist_melt.groupby("variable")["Fecha"].idxmax()
    hist_latest = hist_melt.loc[idx_hr, ["variable", "valor_real"]]

    # Proyecciones del escenario (tomamos escenario = 'normal' para referencia)
    with _engine.connect() as conn:
        df_proj_long = pd.read_sql(
            text(
                """
                SELECT fecha, variable, escenario, valor_proyectado
                FROM forecast_driver_scenarios
                WHERE scenario_name = :s
                """
            ),
            conn,
            params={"s": scenario_name},
            parse_dates=["fecha"],
        )

    df_proj_normal = df_proj_long[df_proj_long["escenario"].str.lower() == "normal"].copy()
    if df_proj_normal.empty:
        proj_latest = pd.DataFrame(columns=["variable", "valor_proyectado"])
    else:
        idx_p = df_proj_normal.groupby("variable")["fecha"].idxmax()
        proj_latest = df_proj_normal.loc[idx_p, ["variable", "valor_proyectado"]]

    df = df_vars.merge(hist_latest, on="variable", how="left").merge(
        proj_latest, on="variable", how="left"
    )

    # Enriquecimiento con cat√°logo (Tipo / Por qu√© / Fuente sugerida)
    def _get_cat(v, field, default):
        k = normalize_driver_key(v)
        return DRIVER_CATALOG.get(k, {}).get(field, default)

    df["Tipo"] = df["variable"].apply(lambda v: _get_cat(v, "tipo", "Driver macro / de negocio"))
    df["Por_que"] = df["variable"].apply(lambda v: _get_cat(v, "porque", "Driver relevante para el forecast automotriz."))
    df["Fuente_sugerida"] = df["variable"].apply(lambda v: _get_cat(v, "fuente", "Maresa / fuentes internas y p√∫blicas."))

    # (Opcional) si ya usas "Descripcion" y "Fuente" en la UI, puedes mapear:
    df["Descripcion"] = df["Por_que"]
    df["Fuente"] = df["Fuente_sugerida"]

    # Variaci√≥n porcentual entre el √∫ltimo valor real y el proyectado
    df["Variacion_pct"] = np.where(
        df["valor_real"].notna()
        & (df["valor_real"] != 0)
        & df["valor_proyectado"].notna(),
        (df["valor_proyectado"] / df["valor_real"] - 1) * 100.0,
        np.nan,
    )

    return df


# =============================
# DESAGREGACI√ìN JER√ÅRQUICA
# =============================

@st.cache_data
def calculate_desagregado(df_total_forecast, df_real_granular, meses_share=3):
    """
    Desagrega el forecast total por segmento/marca/modelo/provincia (top-down):

      - Share de segmento: usando TODO el hist√≥rico antes del inicio del forecast.
      - Share de modelo dentro de segmento: usando solo los √∫ltimos `meses_share` meses reales.

    df_total_forecast:
        index = fecha, columnas ['Ventas_Normal','Ventas_Optimista','Ventas_Pesimista']
    df_real_granular:
        columnas ['Fecha','segmento','marca','modelo','provincia','Unidades']
    """
    if df_total_forecast.empty or df_real_granular.empty:
        return pd.DataFrame()

    forecast_start_date = df_total_forecast.index.min()
    df_hist_for_share = df_real_granular[df_real_granular['Fecha'] < forecast_start_date].copy()

    if df_hist_for_share.empty:
        st.error("No hay hist√≥rico antes del inicio del forecast para calcular shares.")
        return pd.DataFrame()

    last_real_date = df_hist_for_share['Fecha'].max()

    # 1) Share por segmento (toda la historia)
    seg_hist = (
        df_hist_for_share
        .groupby('segmento')['Unidades']
        .sum()
        .rename('Unidades_hist_segmento')
        .reset_index()
    )

    total_hist = seg_hist['Unidades_hist_segmento'].sum()
    if total_hist == 0:
        st.error("Hist√≥rico vac√≠o para share por segmento.")
        return pd.DataFrame()

    seg_hist['Share_segmento_hist'] = seg_hist['Unidades_hist_segmento'] / total_hist

    # 2) Share por modelo √∫ltimos N meses
    share_start_date = last_real_date - pd.DateOffset(months=meses_share - 1)
    df_share_period = df_hist_for_share[
        (df_hist_for_share['Fecha'] >= share_start_date) &
        (df_hist_for_share['Fecha'] <= last_real_date)
    ].copy()

    if df_share_period.empty:
        st.error(
            f"No se encontraron ventas en los √∫ltimos {meses_share} meses "
            f"para calcular el share por modelo."
        )
        return pd.DataFrame()

    granular_cols = ['segmento', 'marca', 'modelo', 'provincia']

    model_3m = (
        df_share_period
        .groupby(granular_cols)['Unidades']
        .sum()
        .rename('Unidades_3m_modelo')
        .reset_index()
    )

    seg_3m = (
        df_share_period
        .groupby('segmento')['Unidades']
        .sum()
        .rename('Unidades_3m_segmento')
        .reset_index()
    )

    model_3m = model_3m.merge(seg_3m, on='segmento', how='left')
    model_3m['Share_model_3m'] = model_3m['Unidades_3m_modelo'] / model_3m['Unidades_3m_segmento']
    model_3m['Share_model_3m'] = model_3m['Share_model_3m'].fillna(0).clip(lower=0)
    model_3m['sum_seg'] = model_3m.groupby('segmento')['Share_model_3m'].transform('sum')
    model_3m['Share_model_3m_norm'] = np.where(
        model_3m['sum_seg'] > 0,
        model_3m['Share_model_3m'] / model_3m['sum_seg'],
        0
    )

    df_shares = model_3m.merge(
        seg_hist[['segmento', 'Share_segmento_hist']],
        on='segmento',
        how='left'
    )
    df_shares['Share'] = df_shares['Share_segmento_hist'] * df_shares['Share_model_3m_norm']
    df_shares = df_shares[granular_cols + ['Share']]

    # 3) Expandir forecast total x shares
    df_shares['key'] = 1
    df_total_forecast_temp = df_total_forecast.reset_index()
    df_total_forecast_temp['key'] = 1

    df_mega = df_total_forecast_temp.merge(df_shares, on='key').drop(columns=['key'])

    # Map columnas a nombres de escenario
    escenarios_map = {
        'Ventas_Normal': 'Normal',
        'Ventas_Optimista': 'Optimista',
        'Ventas_Pesimista': 'Pesimista'
    }
    df_mega = df_mega.rename(columns=escenarios_map)
    escenarios_presentes = [v for v in escenarios_map.values() if v in df_mega.columns]

    dfs_final = []
    for esc in escenarios_presentes:
        df_esc = df_mega.copy()
        df_esc['Unidades_Decimal'] = df_esc[esc] * df_esc['Share']
        df_esc['Unidades'] = np.round(df_esc['Unidades_Decimal'], 0)

        # Ajuste de redondeo por mes
        df_esc_list = []
        for f in df_esc['fecha'].unique():
            df_mes = df_esc[df_esc['fecha'] == f].copy()
            total_proy = df_mes[esc].iloc[0]
            total_red = df_mes['Unidades'].sum()
            dif = total_proy - total_red
            if dif != 0 and not df_mes.empty:
                idx_max = df_mes['Unidades_Decimal'].idxmax()
                df_mes.loc[idx_max, 'Unidades'] += dif
            df_esc_list.append(df_mes)

        if not df_esc_list:
            continue

        df_esc_final = pd.concat(df_esc_list)
        df_esc_final['Escenario'] = esc
        df_esc_final = df_esc_final.drop(
            columns=[c for c in escenarios_presentes if c in df_esc_final.columns] +
                    ['Share', 'Unidades_Decimal']
        )
        dfs_final.append(df_esc_final)

    if not dfs_final:
        return pd.DataFrame()

    df_desagregado = pd.concat(dfs_final, ignore_index=True)
    df_desagregado = df_desagregado.rename(columns={'fecha': 'Fecha'})
    df_desagregado['Tipo'] = 'Proyectado'
    return df_desagregado


# =============================
# LOGIN
# =============================

if not st.session_state['logged_in']:
    st.title("Bienvenido a la Plataforma de Forecast")

    with st.form("login_form"):
        st.subheader("Inicio de Sesi√≥n")
        email = st.text_input("Correo Electr√≥nico (@corpmaresa.com.ec)")
        password = st.text_input("Contrase√±a", type="password")
        submitted = st.form_submit_button("Ingresar")

        if submitted:
            success, message, is_admin = login_user(email, password)
            if success:
                st.session_state['logged_in'] = True
                st.session_state['is_admin'] = is_admin
                st.session_state['email'] = email
                st.rerun()
            else:
                st.error(message)

    st.info("¬øNo tienes cuenta? Reg√≠strate aqu√≠:")

    if st.button("Ir a Registro"):
        st.switch_page("pages/3_Register.py")

    st.stop()


# =============================
# APP PRINCIPAL (LOGUEADO)
# =============================

render_sidebar()

engine = get_db_engine()
st.title("üìà Forecast Industria Automotriz ‚Äì Ecuador")

# 1) Cargar datos b√°sicos
with st.spinner("Cargando datos..."):
    forecast_names = load_all_forecast_names()
    df_real_granular = load_all_granular_sales()

if not forecast_names:
    st.error("No hay proyecciones guardadas en forecast_final_projections.")
    st.stop()

if df_real_granular.empty:
    st.error("No hay ventas hist√≥ricas en sales_granular.")
    st.stop()

# 2) Seleccionar Proyecci√≥n Maestra (esto aplica a TODA la app)
st.subheader("Selecci√≥n de Proyecci√≥n Maestra")
col_f1, col_f2 = st.columns([2, 3])
with col_f1:
    selected_forecast_name = st.selectbox(
        "Proyecci√≥n guardada:",
        options=forecast_names,
        index=0
    )
    st.session_state['selected_forecast_name'] = selected_forecast_name

# Cargar forecast total (industria) para esa proyecci√≥n
df_total_forecast = load_selected_forecast(selected_forecast_name)
st.session_state['df_total_forecast'] = df_total_forecast

if df_total_forecast.empty:
    st.error("La proyecci√≥n seleccionada no tiene datos.")
    st.stop()

# Preparamos DF de forecast melt para facilidad
df_proy_total = df_total_forecast.reset_index().melt(
    id_vars='fecha',
    value_vars=['Ventas_Normal', 'Ventas_Optimista', 'Ventas_Pesimista'],
    var_name='Escenario_col',
    value_name='Unidades'
)
df_proy_total['Escenario'] = df_proy_total['Escenario_col'].map({
    'Ventas_Normal': 'Normal',
    'Ventas_Optimista': 'Optimista',
    'Ventas_Pesimista': 'Pesimista'
})
df_proy_total = df_proy_total.drop(columns=['Escenario_col'])
df_proy_total = df_proy_total.rename(columns={'fecha': 'Fecha'})

# Real total por fecha
df_real_total = df_real_granular.groupby('Fecha')['Unidades'].sum().reset_index()

# =============================
# TABS PRINCIPALES
# =============================

tab_overview, tab_modelos = st.tabs([
    "Visi√≥n General Proyectada",
    "Detalle por modelo / versi√≥n"
])


# -------------------------------------------------
# TAB 1: VISI√ìN GENERAL PROYECTADA
# -------------------------------------------------
with tab_overview:
    st.header("Visi√≥n General Proyectada")

    # Filtro de escenario SOLO para esta pesta√±a
    escenarios_disponibles = sorted(df_proy_total['Escenario'].unique())
    escenario_overview = st.radio(
        "Escenario para an√°lisis (solo afecta algunas gr√°ficas):",
        options=escenarios_disponibles,
        index=0,
        horizontal=True
    )

    # 1) FICHA T√âCNICA DE LA PROYECCI√ìN
    with st.expander("üìë Ficha T√©cnica de la Proyecci√≥n", expanded=False):

        df_proj_catalog = load_projection_catalog(engine)

        if df_proj_catalog.empty:
            st.info("No se encontraron proyecciones guardadas en la tabla 'forecast_final_projections'.")
        else:
            # Usar directamente la proyecci√≥n maestra seleccionada arriba
            selected_projection = st.session_state.get("selected_forecast_name")
            df_sel = df_proj_catalog[df_proj_catalog["projection_name"] == selected_projection]

            if df_sel.empty:
                st.warning(
                    "La proyecci√≥n seleccionada en la parte superior no tiene ficha t√©cnica registrada. "
                    "Se mostrar√° la primera proyecci√≥n disponible."
                )
                row_sel = df_proj_catalog.iloc[0]
            else:
                row_sel = df_sel.iloc[0]

            projection_name_ft = row_sel["projection_name"]
            segmento_base_ft_raw = row_sel["segmento_base"]
            # Mostrar 'Total Industria' en lugar de 'Total_Filtrado'
            segmento_base_ft = "Total Industria" if segmento_base_ft_raw == "Total_Filtrado" else segmento_base_ft_raw
            modelo_usado_ft = row_sel["modelo_usado"]
            scenario_name_ft = row_sel["scenario_name"]

            col_info_1, col_info_2 = st.columns([0.6, 0.4])
            with col_info_1:
                st.markdown(f"**Proyecci√≥n seleccionada:** `{projection_name_ft}`")
                st.markdown(f"- Segmento base: **{segmento_base_ft}**")
                st.markdown(f"- Modelo usado en la proyecci√≥n final: **{modelo_usado_ft}**")

                if scenario_name_ft is None or (isinstance(scenario_name_ft, float) and np.isnan(scenario_name_ft)):
                    st.markdown("- Escenario de drivers: `No asociado (proyecci√≥n antigua)`")
                else:
                    st.markdown(f"- Escenario de drivers: `{scenario_name_ft}`")

            # Variables (drivers) utilizados
            st.markdown("### üîß Variables (Drivers) utilizados en el escenario")

            if scenario_name_ft is None or (isinstance(scenario_name_ft, float) and np.isnan(scenario_name_ft)):
                st.info(
                    "Esta proyecci√≥n no tiene un escenario de drivers asociado (scenario_name = NULL). "
                    "Probablemente fue generada antes de actualizar el flujo. "
                    "Si quieres ver la ficha completa, vuelve a correr el forecast y guarda la proyecci√≥n de nuevo."
                )
            else:
                df_vars_summary = build_driver_summary_for_scenario(engine, scenario_name_ft)

                if df_vars_summary.empty:
                    st.warning("No se encontraron variables asociadas a este escenario de drivers.")
                else:
                    def _cat(v, field, default="-"):
                        k = normalize_driver_key(v)
                        return DRIVER_CATALOG.get(k, {}).get(field, default)

                    df_vars_summary["Tipo"] = df_vars_summary["variable"].apply(lambda v: _cat(v, "tipo", "Driver macro / de negocio"))
                    df_vars_summary["Por_que"] = df_vars_summary["variable"].apply(lambda v: _cat(v, "porque", "Driver relevante para forecast automotriz."))
                    df_vars_summary["Fuente_sugerida"] = df_vars_summary["variable"].apply(lambda v: _cat(v, "fuente", "Dummy"))


                    df_display = df_vars_summary.copy()
                    df_display = df_display.rename(
                        columns={
                            "variable": "Variable",
                            "Por_que": "Por qu√© se considera para forecast automotriz",
                            "valor_real": "√öltimo valor real",
                            "valor_proyectado": "√öltimo valor proyectado",
                            "Variacion_pct": "Variaci√≥n %",
                            "Fuente_sugerida": "Fuente sugerida",
                        }
                    )

                    # Formateos (miles con punto y % con 1 decimal)
                    def fmt_miles(x):
                        if pd.isna(x):
                            return "-"
                        try:
                            x = float(x)
                        except Exception:
                            return str(x)
                        # 22.000 (punto miles, sin decimales)
                        return f"{x:,.0f}".replace(",", ".")

                    def fmt_pct(x):
                        if pd.isna(x):
                            return "-"
                        try:
                            x = float(x)
                        except Exception:
                            return str(x)
                        # 1 decimal m√°ximo en porcentaje
                        return f"{x:.1f}%".replace(".", ",")

                    if "√öltimo valor real" in df_display.columns:
                        df_display["√öltimo valor real"] = df_display["√öltimo valor real"].apply(fmt_miles)

                    if "√öltimo valor proyectado" in df_display.columns:
                        df_display["√öltimo valor proyectado"] = df_display["√öltimo valor proyectado"].apply(fmt_miles)

                    if "Variaci√≥n %" in df_display.columns:
                        df_display["Variaci√≥n %"] = df_display["Variaci√≥n %"].apply(fmt_pct)


                    columnas_orden = [
                        "Variable",
                        "Tipo",
                        "Por qu√© se considera para forecast automotriz",
                        "√öltimo valor real",
                        "√öltimo valor proyectado",
                        "Variaci√≥n %",
                        "Fuente sugerida",
                    ]
                    columnas_orden = [c for c in columnas_orden if c in df_display.columns]


                    st.dataframe(
                        df_display[columnas_orden],
                        use_container_width=True,
                        hide_index=True,
                    )

                    n_total = len(df_display)
                    n_dummy = df_display["Variable"].astype(str).str.upper().isin(DUMMY_VARS_LIST).sum()
                    n_cont = n_total - n_dummy

                    st.caption(
                        f"Esta proyecci√≥n utiliza **{n_total} drivers**: "
                        f"{n_cont} cuantitativos (PIB, Riesgo Pa√≠s, tasas, etc.) y "
                        f"{n_dummy} dummies de eventos (Paros, IVA, COVID, elecciones, utilidades...)."
                    )

            st.markdown("---")

            # M√©tricas de modelos y modelo ganador
            col_head_m, col_pop_m = st.columns([0.7, 0.3])
            with col_head_m:
                st.markdown("### üß† Modelos evaluados y errores (Backtest)")
            with col_pop_m:
                with st.popover("‚ÑπÔ∏è Modelos y m√©tricas", use_container_width=True):
                    st.markdown(
                        """
                        **Modelos incluidos (ejemplos):**
                        - **RandomForest:** bosque de √°rboles de decisi√≥n, captura relaciones no lineales y es robusto a outliers.
                        - **XGBoost:** algoritmo de *gradient boosting* muy potente para datos tabulares y relaciones complejas.
                        - **SARIMAX:** modelo cl√°sico de series de tiempo con estacionalidad y variables explicativas (drivers).
                        - **Prophet:** modelo aditivo (tendencia + estacionalidad + festivos/eventos) orientado a series de negocio.

                        **M√©tricas (MAPE / MAE / RMSE):**
                        - **MAPE (%):** mide el error *relativo* promedio.  
                          Ej: un MAPE del 6% significa que, en promedio, el modelo se equivoca un 6% sobre las ventas reales.
                        - **MAE:** error absoluto promedio en **unidades**.  
                          Ej: MAE = 500 ‚Üí en promedio el modelo se equivoca en 500 veh√≠culos por mes.
                        - **RMSE:** error cuadr√°tico medio. Penaliza m√°s los errores grandes
                          y es √∫til para medir el riesgo de desviaciones fuertes.
                        """
                    )

            df_run_ft, df_metrics_ft = load_projection_metrics(engine, projection_name_ft)

            if df_metrics_ft.empty:
                st.warning(
                    "No se encontraron m√©tricas de backtest para esta proyecci√≥n en "
                    "'forecast_runs' / 'forecast_model_metrics'."
                )
            else:
                df_metrics_show = df_metrics_ft.copy()
                df_metrics_show["MAPE (%)"] = (df_metrics_show["mape"]).round(2)
                df_metrics_show["MAE"] = df_metrics_show["mae"].round(0).astype(int)
                df_metrics_show["RMSE"] = df_metrics_show["rmse"].round(0).astype(int)

                df_metrics_show = df_metrics_show[["model_name", "MAPE (%)", "MAE", "RMSE"]]

                st.dataframe(
                    df_metrics_show.rename(columns={"model_name": "Modelo"}).sort_values("MAPE (%)"),
                    use_container_width=True,
                    hide_index=True,
                )

                if not df_run_ft.empty:
                    row_run = df_run_ft.iloc[0]
                    best_model = row_run["best_model"]
                    best_mape = row_run["best_mape"]
                    best_mae = row_run["best_mae"]
                    best_rmse = row_run["best_rmse"]
                    train_start = pd.to_datetime(row_run["train_start"]).date()
                    train_end = pd.to_datetime(row_run["train_end"]).date()
                    test_start = pd.to_datetime(row_run["test_start"]).date()
                    test_end = pd.to_datetime(row_run["test_end"]).date()
                    horizon = int(row_run["horizon_months"])

                    st.markdown("### üèÜ Modelo Ganador y Justificaci√≥n")

                    col_w1, col_w2 = st.columns([0.4, 0.6])

                    with col_w1:
                        st.metric("Modelo Ganador", best_model)
                        st.metric("MAPE Backtest", f"{best_mape:.2f} %")
                        st.metric("RMSE", f"{best_rmse:,.0f}")

                    with col_w2:
                        st.markdown(
                            f"""
                            **¬øPor qu√© gan√≥ `{best_model}`?**

                            - Se ejecut√≥ un **backtest walk-forward** sobre el hist√≥rico de ventas del segmento **{segmento_base_ft}**.
                            - Per√≠odo de entrenamiento: **{train_start} ‚Üí {train_end}**  
                            - Per√≠odo de prueba (validaci√≥n): **{test_start} ‚Üí {test_end}**  
                            - Horizonte de prueba por corrida: **{horizon} meses**.
                            - El modelo ganador obtuvo el **menor MAPE** (error porcentual medio absoluto) en las pruebas,
                              comparado contra los otros modelos (RandomForest, XGBoost, SARIMAX, Prophet).
                            - Adem√°s, el RMSE de `{best_model}` ({best_rmse:,.0f} unidades) indica que su error t√≠pico en unidades
                              es coherente con la escala del mercado.
                            """
                        )
                else:
                    st.info(
                        "Hay m√©tricas por modelo en 'forecast_model_metrics', pero no un resumen en 'forecast_runs'. "
                        "Revisa si se guard√≥ correctamente la corrida."
                    )

    # 2) Pron√≥stico Total (Real + TODOS los escenarios)
    st.subheader("Pron√≥stico de Ventas (Total Industria)")
    st.markdown(
        "Proyecci√≥n mensual de ventas de la industria automotriz. "
        "Se muestra el hist√≥rico (real) y los tres escenarios de forecast (Normal, Optimista y Pesimista). "
        "Este gr√°fico **no** se ve afectado por el filtro de escenario."
    )

    df_real_chart = df_real_total.copy()
    df_real_chart['Escenario'] = 'Real'
    df_real_chart = df_real_chart.rename(columns={'Fecha': 'Fecha', 'Unidades': 'Ventas'})

    df_proy_chart = df_proy_total.copy().rename(columns={'Unidades': 'Ventas'})
    df_forecast_chart = pd.concat([df_real_chart, df_proy_chart], ignore_index=True)

    chart_forecast = (
        alt.Chart(df_forecast_chart)
        .mark_line(point=True)
        .encode(
            x=alt.X('Fecha:T', title='Fecha'),
            y=alt.Y('Ventas:Q', title='Unidades'),
            color=alt.Color('Escenario:N', title='Escenario'),
            tooltip=['Fecha:T', 'Escenario:N', alt.Tooltip('Ventas:Q', format=',.0f')]
        )
        .interactive()
    )
    st.altair_chart(chart_forecast, use_container_width=True)

    # 2) Crecimiento Anual (seg√∫n escenario seleccionado)
    st.subheader("Crecimiento Anual de la Industria")
    st.markdown(
        "Comparaci√≥n de las ventas anuales reales vs. las ventas proyectadas bajo el "
        f"**escenario {escenario_overview}**. Para el a√±o donde empieza el forecast se suma "
        "**real + proyecci√≥n**; los a√±os posteriores son solo proyecci√≥n."
    )

    try:
        # --- 2.1 Real total ---
        df_real_anual = df_real_total.copy()
        df_real_anual['Fecha'] = pd.to_datetime(df_real_anual['Fecha'])
        df_real_anual['Year'] = df_real_anual['Fecha'].dt.year
        df_real_group = df_real_anual.groupby('Year')['Unidades'].sum().rename('Real')

        last_real_date = df_real_anual['Fecha'].max()

        # --- 2.2 Forecast solo del escenario seleccionado ---
        df_proj_sel = df_proy_total[df_proy_total['Escenario'] == escenario_overview].copy()
        df_proj_sel['Fecha'] = pd.to_datetime(df_proj_sel['Fecha'])

        if not df_proj_sel.empty:
            df_proj_future = df_proj_sel[df_proj_sel['Fecha'] > last_real_date].copy()
            if not df_proj_future.empty:
                df_proj_future['Year'] = df_proj_future['Fecha'].dt.year
                df_proj_group = df_proj_future.groupby('Year')['Unidades'].sum().rename('Proyectado')
            else:
                df_proj_group = pd.Series(dtype=float, name='Proyectado')
        else:
            df_proj_group = pd.Series(dtype=float, name='Proyectado')

        # --- 2.3 Unir real + proyecci√≥n por a√±o ---
        df_growth = pd.concat([df_real_group, df_proj_group], axis=1).fillna(0.0)
        df_growth.index.name = 'A√±o'
        df_growth = df_growth.reset_index()

        df_growth['Total'] = df_growth['Real'] + df_growth['Proyectado']

        def clasificar_tipo(row):
            y = row['A√±o']
            if row['Proyectado'] == 0 and row['Real'] > 0:
                return 'Solo real'
            if row['Real'] > 0 and row['Proyectado'] > 0:
                return 'Real + proyecci√≥n'
            if row['Real'] == 0 and row['Proyectado'] > 0:
                return 'Solo proyecci√≥n'
            return 'Sin datos'

        df_growth['Tipo'] = df_growth.apply(clasificar_tipo, axis=1)

        df_growth = df_growth.sort_values('A√±o').reset_index(drop=True)
        df_growth['Crecimiento %'] = 0.0
        for i in range(1, len(df_growth)):
            prev = df_growth.loc[i - 1, 'Total']
            curr = df_growth.loc[i, 'Total']
            if prev > 0:
                df_growth.loc[i, 'Crecimiento %'] = (curr / prev - 1) * 100

        df_growth_display = df_growth.copy()
        df_growth_display['Real'] = df_growth_display['Real'].round(0).astype(int)
        df_growth_display['Proyectado'] = df_growth_display['Proyectado'].round(0).astype(int)
        df_growth_display['Total'] = df_growth_display['Total'].round(0).astype(int)
        df_growth_display['Crecimiento %'] = df_growth_display['Crecimiento %'].map(lambda x: f"{x:.1f}%")

        st.dataframe(df_growth_display, use_container_width=True, hide_index=True)

        df_growth_chart = df_growth.copy()
        df_growth_chart['Label'] = df_growth_chart['Total'].map(lambda x: f"{x:,.0f}")

        chart_growth = (
            alt.Chart(df_growth_chart)
            .mark_bar()
            .encode(
                x=alt.X('A√±o:O', title='A√±o'),
                y=alt.Y('Total:Q', title='Ventas anuales (Total)'),
                color=alt.Color('Tipo:N', title='Tipo de a√±o'),
                tooltip=[
                    alt.Tooltip('A√±o:O', title='A√±o'),
                    alt.Tooltip('Real:Q', format=',.0f', title='Real'),
                    alt.Tooltip('Proyectado:Q', format=',.0f', title='Proyectado'),
                    alt.Tooltip('Total:Q', format=',.0f', title='Total'),
                    alt.Tooltip('Crecimiento %:Q', format='.1f', title='Crecimiento %')
                ]
            )
        )

        text_growth = chart_growth.mark_text(
            dy=-5,
            color='black'
        ).encode(text='Label:N')

        st.altair_chart(chart_growth + text_growth, use_container_width=True)

    except Exception as e:
        st.error(f"Error en gr√°fico de Crecimiento Anual: {e}")
        st.exception(e)

    # 3) An√°lisis de Estacionalidad
    st.subheader("An√°lisis de Estacionalidad")
    st.markdown(
        "Gr√°fico de barras mensualizado por a√±o. En el eje X se muestran los meses, "
        "en el eje Y las unidades vendidas y en la leyenda los **a√±os**. "
        "Se toman los **√∫ltimos 3 a√±os**, combinando datos reales y proyectados "
        f"del escenario **{escenario_overview}**. Sobre cada barra se muestra la "
        "variaci√≥n porcentual vs. el mismo mes del a√±o anterior."
    )

    # --- 3.1 Combinar real + proyectado (solo escenario seleccionado) ---
    df_real_est = df_real_total.copy()
    df_real_est['Fecha'] = pd.to_datetime(df_real_est['Fecha'])

    df_proy_est = df_proy_total[
        df_proy_total['Escenario'] == escenario_overview
    ].copy()
    df_proy_est['Fecha'] = pd.to_datetime(df_proy_est['Fecha'])

    last_real_date = df_real_est['Fecha'].max()

    df_hist = df_real_est.copy()
    df_fut = df_proy_est[df_proy_est['Fecha'] > last_real_date].copy()
    df_fut = df_fut.rename(columns={'Unidades': 'Unidades'})

    df_comb = pd.concat(
        [df_hist[['Fecha', 'Unidades']], df_fut[['Fecha', 'Unidades']]],
        ignore_index=True
    )

    df_comb['Year'] = df_comb['Fecha'].dt.year
    df_comb['MesNum'] = df_comb['Fecha'].dt.month
    df_comb['Mes'] = df_comb['MesNum'].map({
        1: 'Ene', 2: 'Feb', 3: 'Mar', 4: 'Abr', 5: 'May', 6: 'Jun',
        7: 'Jul', 8: 'Ago', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dic'
    })

    df_est_all = (
        df_comb
        .groupby(['Mes', 'MesNum', 'Year'])['Unidades']
        .sum()
        .reset_index()
    )

    df_est_all = df_est_all.sort_values(['MesNum', 'Year']).reset_index(drop=True)
    df_est_all['VarPct'] = np.nan

    for mes in df_est_all['MesNum'].unique():
        sub_idx = df_est_all['MesNum'] == mes
        sub = df_est_all.loc[sub_idx].copy().sort_values('Year')
        prev_units = None
        for i, row in sub.iterrows():
            if prev_units is not None and prev_units > 0:
                df_est_all.loc[i, 'VarPct'] = (row['Unidades'] / prev_units - 1) * 100
            prev_units = row['Unidades']

    years_available = sorted(df_est_all['Year'].unique())
    if len(years_available) >= 3:
        last3_years = years_available[-3:]
    else:
        last3_years = years_available

    df_est_group = df_est_all[df_est_all['Year'].isin(last3_years)].copy()

    def format_varpct(x):
        if pd.isna(x):
            return ""
        return f"{x:.1f}%"

    df_est_group['Label'] = df_est_group['VarPct'].apply(format_varpct)

    mes_order = ['Ene', 'Feb', 'Mar', 'Abr', 'May', 'Jun',
                 'Jul', 'Ago', 'Sep', 'Oct', 'Nov', 'Dic']
    
    # --- justo antes de base_est = alt.Chart(df_est_group) ---
    df_est_group["YearStr"] = df_est_group["Year"].astype(str)
    year_domain = [str(y) for y in sorted(df_est_group["Year"].unique())]

    color_scale_year = alt.Scale(
        domain=year_domain,
        scheme="tableau10"   # paleta categ√≥rica (colores bien distintos)
    )

    base_est = alt.Chart(df_est_group)

    chart_est = (
        base_est
        .mark_bar()
        .encode(
            x=alt.X('Mes:N', sort=mes_order, title='Mes'),
            xOffset=alt.XOffset('YearStr:N'),
            y=alt.Y('Unidades:Q', title='Unidades'),
            color=alt.Color('YearStr:N', title='A√±o', scale=color_scale_year, sort=year_domain),
            tooltip=[
                alt.Tooltip('YearStr:N', title='A√±o'),
                alt.Tooltip('Mes:N', title='Mes'),
                alt.Tooltip('Unidades:Q', format=',.0f', title='Unidades'),
                alt.Tooltip('VarPct:Q', format='.1f', title='Var. vs a√±o anterior (%)')
            ]
        )
    )

    text_est = (
        base_est
        .mark_text(dy=-5, size=10)
        .encode(
            x=alt.X('Mes:N', sort=mes_order),
            xOffset=alt.XOffset('YearStr:N'),
            y=alt.Y('Unidades:Q'),
            text='Label:N'
        )
    )

    st.altair_chart(chart_est + text_est, use_container_width=True)

    # 4) Evoluci√≥n de Share por Segmento
    st.subheader("Evoluci√≥n de Share por Segmento")
    st.markdown(
        "Share mensual de cada segmento sobre el total industria. "
        "Las l√≠neas continuas son hist√≥ricas; las punteadas son proyecciones "
        "estimadas a partir de la tendencia y estacionalidad del share real "
        "usando el horizonte del forecast seleccionado."
    )

    try:
        df_share_real = (
            df_real_granular
            .groupby(['Fecha', 'segmento'])['Unidades']
            .sum()
            .reset_index()
        )
        df_share_real['Total_mes'] = df_share_real.groupby('Fecha')['Unidades'].transform('sum')
        df_share_real = df_share_real[df_share_real['Total_mes'] > 0]
        df_share_real['Share'] = df_share_real['Unidades'] / df_share_real['Total_mes']
        df_share_real['Tipo'] = 'Real'

        future_dates = list(df_total_forecast.index.unique())
        df_share_proy = pd.DataFrame()

        if future_dates:
            rows = []
            h = len(future_dates)
            eps = 1e-6

            for seg in df_share_real['segmento'].unique():
                df_seg = (
                    df_share_real[df_share_real['segmento'] == seg]
                    .sort_values('Fecha')
                    .dropna(subset=['Share'])
                    .copy()
                )
                if df_seg.empty:
                    continue

                df_seg['mes'] = df_seg['Fecha'].dt.month

                cutoff_season = df_seg['Fecha'].max() - pd.DateOffset(years=4)
                df_season = df_seg[df_seg['Fecha'] >= cutoff_season].copy()
                if df_season.empty:
                    df_season = df_seg.copy()

                mean_global = df_season['Share'].mean()
                if mean_global <= 0:
                    continue

                monthly_mean = df_season.groupby('mes')['Share'].mean()
                factores = (monthly_mean / mean_global).reindex(range(1, 13), fill_value=1.0)

                df_seg['Factor_mes'] = df_seg['mes'].map(factores).fillna(1.0)
                df_seg['Share_deseason'] = df_seg['Share'] / df_seg['Factor_mes']

                df_seg['t'] = np.arange(len(df_seg))
                y = df_seg['Share_deseason'].clip(eps, 1 - eps).values

                if len(df_seg) >= 6:
                    y_logit = np.log(y / (1 - y))
                    X = df_seg[['t']].values
                    model = LinearRegression()
                    model.fit(X, y_logit)

                    t_future = np.arange(len(df_seg), len(df_seg) + h).reshape(-1, 1)
                    y_logit_future = model.predict(t_future)
                    y_future_deseason = 1 / (1 + np.exp(-y_logit_future))
                else:
                    last_n = min(12, len(df_seg))
                    y_future_deseason = np.repeat(
                        df_seg.tail(last_n)['Share_deseason'].mean(),
                        h
                    )

                for fecha_f, y_des in zip(future_dates, y_future_deseason):
                    mes_f = pd.to_datetime(fecha_f).month
                    factor_mes_f = float(factores.get(mes_f, 1.0))
                    share_f = float(np.clip(y_des * factor_mes_f, eps, 1 - eps))

                    rows.append({
                        'Fecha': pd.to_datetime(fecha_f),
                        'segmento': seg,
                        'Share': share_f,
                        'Tipo': 'Proyectado'
                    })

            df_share_proy = pd.DataFrame(rows)
            if not df_share_proy.empty:
                df_share_proy['sum_mes'] = df_share_proy.groupby('Fecha')['Share'].transform('sum')
                df_share_proy['Share'] = np.where(
                    df_share_proy['sum_mes'] > 0,
                    df_share_proy['Share'] / df_share_proy['sum_mes'],
                    df_share_proy['Share']
                )

        df_share_all = pd.concat([df_share_real, df_share_proy], ignore_index=True)

        chart_share = (
            alt.Chart(df_share_all)
            .mark_line()
            .encode(
                x=alt.X('Fecha:T', title='Fecha'),
                y=alt.Y('Share:Q', title='Share segmento', axis=alt.Axis(format='%')),
                color=alt.Color('segmento:N', title='Segmento'),
                strokeDash=alt.StrokeDash('Tipo:N', title='Tipo'),
                tooltip=[
                    alt.Tooltip('Fecha:T', title='Fecha'),
                    alt.Tooltip('segmento:N', title='Segmento'),
                    alt.Tooltip('Tipo:N', title='Tipo'),
                    alt.Tooltip('Share:Q', title='Share', format='.1%')
                ]
            )
            .interactive()
        )
        st.altair_chart(chart_share, use_container_width=True)

        if 'df_share_proy' in locals() and not df_share_proy.empty:
            df_share_proy_seg = df_share_proy[['Fecha', 'segmento', 'Share']].copy()
        else:
            df_share_proy_seg = pd.DataFrame()

    except Exception as e:
        st.error("Error al generar la evoluci√≥n de share por segmento.")
        st.exception(e)

    # 5) Unidades por segmento (Real + Proyecci√≥n del escenario seleccionado)
    st.subheader("Unidades por Segmento (Real + Proyecci√≥n)")
    st.markdown(
        "Distribuci√≥n de ventas por segmento a lo largo del tiempo. "
        "Incluye hist√≥rico real y forecast del escenario seleccionado: "
        f"**{escenario_overview}**."
    )

    df_seg_real = (
        df_real_granular
        .groupby(['Fecha', 'segmento'])['Unidades']
        .sum()
        .reset_index()
    )
    df_seg_real['Tipo'] = 'Real'
    df_seg_real['Fecha'] = pd.to_datetime(df_seg_real['Fecha'])

    df_seg_all = df_seg_real.copy()

    if 'df_share_proy_seg' not in locals() or df_share_proy_seg.empty:
        st.warning("No hay shares proyectados por segmento; se muestran solo datos reales.")
    else:
        df_total_esc = df_proy_total[df_proy_total['Escenario'] == escenario_overview].copy()
        df_total_esc = df_total_esc.rename(columns={'Unidades': 'Unidades_total'})
        df_total_esc['Fecha'] = pd.to_datetime(df_total_esc['Fecha'])

        df_seg_proj = df_share_proy_seg.merge(
            df_total_esc,
            on='Fecha',
            how='inner'
        )
        df_seg_proj['Unidades'] = df_seg_proj['Share'] * df_seg_proj['Unidades_total']
        df_seg_proj['Tipo'] = f'Proyectado_{escenario_overview}'

        df_seg_all = pd.concat(
            [df_seg_real, df_seg_proj[['Fecha', 'segmento', 'Unidades', 'Tipo']]],
            ignore_index=True
        )

    chart_seg = (
        alt.Chart(df_seg_all)
        .mark_bar()
        .encode(
            x=alt.X('Fecha:T', title='Fecha'),
            y=alt.Y('Unidades:Q', title='Unidades'),
            color=alt.Color('segmento:N', title='Segmento'),
            tooltip=[
                alt.Tooltip('Fecha:T', title='Fecha'),
                alt.Tooltip('segmento:N', title='Segmento'),
                alt.Tooltip('Tipo:N', title='Tipo'),
                alt.Tooltip('Unidades:Q', format=',.0f', title='Unidades')
            ]
        )
    )

    st.altair_chart(chart_seg.interactive(), use_container_width=True)


# -------------------------------------------------
# TAB 2: DETALLE POR MODELO / VERSI√ìN
# -------------------------------------------------
with tab_modelos:
    st.header("Detalle por modelo / versi√≥n")

    st.markdown(
        "En esta pesta√±a se calcula la **desagregaci√≥n a nivel modelo/versi√≥n**.\n"
        "Las ventas por modelo se estiman a partir del forecast total de la industria, "
        "usando un share de modelo dentro de cada segmento calculado con los √∫ltimos "
        "**N meses** de ventas reales."
    )

    # =============================
    # CONFIGURACI√ìN + FILTROS (EXPANDER)
    # =============================
    with st.expander("Configuraci√≥n de Desagregaci√≥n y Filtros de Detalle", expanded=True):

        # --- Configuraci√≥n de desagregaci√≥n ---
        st.subheader("Configuraci√≥n de Desagregaci√≥n")
        col_d1, col_d2 = st.columns([2, 1])
        with col_d1:
            meses_share_modelo = st.slider(
                "Meses recientes para calcular el share por modelo:",
                min_value=1,
                max_value=12,
                value=st.session_state['meses_share_modelo'],
                help="N√∫mero de meses recientes para distribuir el forecast a modelos."
            )
        with col_d2:
            st.write("")
            st.write("")
            calc_button = st.button("Calcular Mercado Detallado", type="primary")

        st.markdown("---")

        # --- Filtros de detalle por modelo / versi√≥n ---
        st.subheader("Filtros de Detalle por modelo / versi√≥n")

        segmentos_disp = sorted(df_real_granular['segmento'].unique())
        marcas_disp = sorted(df_real_granular['marca'].unique())
        modelos_disp = sorted(df_real_granular['modelo'].unique())
        provincias_disp = sorted(df_real_granular['provincia'].unique())

        col_f1, col_f2 = st.columns(2)
        with col_f1:
            filt_segmento = st.multiselect("Segmento", ["Todas"] + segmentos_disp, default=["Todas"])
            filt_marca = st.multiselect("Marca", ["Todas"] + marcas_disp, default=["Todas"])
        with col_f2:
            filt_modelo = st.multiselect("Modelo", ["Todas"] + modelos_disp, default=["Todas"])
            filt_provincia = st.multiselect("Provincia", ["Todas"] + provincias_disp, default=["Todas"])

        # Rango de fechas para detalle
        min_date_hist = df_real_granular['Fecha'].min().date()
        max_date_hist = df_real_granular['Fecha'].max().date()
        date_range_det = st.date_input(
            "Rango de fechas (detalle):",
            value=(min_date_hist, max_date_hist),
            min_value=min_date_hist,
            max_value=max_date_hist
        )

        try:
            det_start_date, det_end_date = date_range_det
        except ValueError:
            det_start_date, det_end_date = (min_date_hist, max_date_hist)

        escenarios_detalle = ['Normal', 'Optimista', 'Pesimista']
        escenario_detalle = st.radio(
            "Escenario (detalle):",
            escenarios_detalle,
            index=0,
            horizontal=True
        )

    if calc_button:
        with st.spinner("Calculando desagregaci√≥n top-down por modelo..."):
            df_desagregado = calculate_desagregado(
                st.session_state['df_total_forecast'],
                df_real_granular,
                meses_share=meses_share_modelo
            )
            if df_desagregado.empty:
                st.error("No se pudo generar la desagregaci√≥n.")
            else:
                st.session_state['df_desagregado'] = df_desagregado
                st.session_state['meses_share_modelo'] = meses_share_modelo
                st.success("Desagregaci√≥n generada correctamente.")

    df_desag = st.session_state['df_desagregado']

    if df_desag is None or df_desag.empty:
        st.info("A√∫n no se ha calculado la desagregaci√≥n. Configura y pulsa **Calcular Mercado Detallado**.")
    else:
        st.markdown(
            f"Desagregaci√≥n calculada usando los √∫ltimos **{st.session_state['meses_share_modelo']}** meses "
            "para el share por modelo."
        )

        df_real_hist = df_real_granular.copy()
        df_real_hist['Tipo'] = 'Real'
        df_real_hist['Escenario'] = 'Real'

        df_union = pd.concat([df_real_hist, df_desag], ignore_index=True)

        seg_filtrar = segmentos_disp if "Todas" in filt_segmento else filt_segmento
        marca_filtrar = marcas_disp if "Todas" in filt_marca else filt_marca
        modelo_filtrar = modelos_disp if "Todas" in filt_modelo else filt_modelo
        prov_filtrar = provincias_disp if "Todas" in filt_provincia else filt_provincia

        df_union_f = df_union[
            (df_union['segmento'].isin(seg_filtrar)) &
            (df_union['marca'].isin(marca_filtrar)) &
            (df_union['modelo'].isin(modelo_filtrar)) &
            (df_union['provincia'].isin(prov_filtrar))
        ].copy()

        df_union_f['Fecha'] = pd.to_datetime(df_union_f['Fecha'])

        df_union_f = df_union_f[
            (df_union_f['Fecha'] >= pd.to_datetime(det_start_date)) &
            (df_union_f['Fecha'] <= pd.to_datetime(det_end_date))
        ]

        df_det_real = df_union_f[df_union_f['Tipo'] == 'Real'].copy()
        df_det_proy = df_union_f[
            (df_union_f['Tipo'] == 'Proyectado') &
            (df_union_f['Escenario'] == escenario_detalle)
        ].copy()

        st.subheader(f"KPIs del Forecast desagregado (Escenario: {escenario_detalle})")
        k1, k2 = st.columns(2)

        if not df_det_proy.empty:
            df_det_proy['Year'] = df_det_proy['Fecha'].dt.year
            proy_por_ano = df_det_proy.groupby('Year')['Unidades'].sum()
            with k1:
                st.markdown("**Proyecci√≥n por A√±o (detalle filtrado)**")
                cols_year = st.columns(len(proy_por_ano))
                for i, (yy, total) in enumerate(proy_por_ano.items()):
                    cols_year[i].metric(label=f"{yy}", value=f"{total:,.0f} un.")
        else:
            with k1:
                st.info("Sin proyecci√≥n para los filtros seleccionados.")

        with k2:
            if not df_det_proy.empty:
                total_proy = df_det_proy.groupby('Fecha')['Unidades'].sum().sum()
                n_meses_proy = df_det_proy['Fecha'].dt.to_period('M').nunique()
                prom_proy = total_proy / n_meses_proy if n_meses_proy > 0 else 0

                if not df_det_real.empty:
                    last_real = df_det_real['Fecha'].max()
                    l12m_ini = last_real - pd.DateOffset(months=11)
                    df_l12m = df_det_real[df_det_real['Fecha'] >= l12m_ini]
                    total_real_l12m = df_l12m.groupby('Fecha')['Unidades'].sum().sum()
                    n_meses_real = df_l12m['Fecha'].dt.to_period('M').nunique()
                    prom_real = total_real_l12m / n_meses_real if n_meses_real > 0 else 0
                    delta = (prom_proy / prom_real - 1) if prom_real > 0 else None
                    st.metric(
                        "Promedio mensual proyectado",
                        f"{prom_proy:,.0f} un.",
                        f"{delta:.1%}" if delta is not None else None,
                        help=f"Promedio real L12M: {prom_real:,.0f} un."
                    )
                else:
                    st.metric("Promedio mensual proyectado", f"{prom_proy:,.0f} un.")
            else:
                st.info("Sin proyecci√≥n para calcular promedios.")

        st.markdown("---")

        st.subheader("Serie de tiempo (Real vs Proyectado ‚Äì filtros aplicados)")

        df_ts_real = df_det_real.groupby('Fecha')['Unidades'].sum().reset_index()
        df_ts_real['Tipo'] = 'Real'

        df_ts_proy = df_det_proy.groupby('Fecha')['Unidades'].sum().reset_index()
        df_ts_proy['Tipo'] = f'Proyectado_{escenario_detalle}'

        df_ts = pd.concat([df_ts_real, df_ts_proy], ignore_index=True)
        df_ts = df_ts.rename(columns={'Unidades': 'Ventas'})

        chart_ts = (
            alt.Chart(df_ts)
            .mark_line(point=True)
            .encode(
                x=alt.X('Fecha:T', title='Fecha'),
                y=alt.Y('Ventas:Q', title='Unidades'),
                color=alt.Color('Tipo:N', title='Tipo'),
                tooltip=['Fecha:T', 'Tipo:N', alt.Tooltip('Ventas:Q', format=',.0f')]
            )
            .interactive()
        )
        st.altair_chart(chart_ts, use_container_width=True)

        st.subheader("Tabla detallada por modelo / versi√≥n")
        st.dataframe(
            df_det_proy.sort_values(['Fecha', 'marca', 'modelo']),
            use_container_width=True,
            hide_index=True
        )

        if not df_det_proy.empty:
            st.subheader("Top 15 modelos por a√±o (Escenario proyectado)")

            years_disp = sorted(df_det_proy['Fecha'].dt.year.unique())
            anio_sel = st.selectbox("A√±o a analizar:", options=years_disp, index=0)

            df_anio = df_det_proy[df_det_proy['Fecha'].dt.year == anio_sel].copy()
            if df_anio.empty:
                st.info("No hay datos para ese a√±o con los filtros actuales.")
            else:
                df_top_modelos = (
                    df_anio
                    .groupby(['marca', 'modelo'])['Unidades']
                    .sum()
                    .reset_index()
                    .sort_values('Unidades', ascending=False)
                    .head(15)
                )

                chart_top = (
                    alt.Chart(df_top_modelos)
                    .mark_bar()
                    .encode(
                        x=alt.X('Unidades:Q', title='Unidades proyectadas'),
                        y=alt.Y('modelo:N', sort='-x', title='Modelo'),
                        color='marca:N',
                        tooltip=['marca:N', 'modelo:N', alt.Tooltip('Unidades:Q', format=',.0f')]
                    )
                )
                st.altair_chart(chart_top, use_container_width=True)